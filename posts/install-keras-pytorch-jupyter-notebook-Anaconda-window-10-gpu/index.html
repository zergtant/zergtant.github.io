<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="tantai"><title>win10下通过Anaconda搭建深度学习环境GPU篇 · 人肉智能</title><meta name="description" content="win10下通过Anaconda搭建深度学习环境GPU篇
 环境准备
Anaconda3-5.3.0-Windows-x86_64 (PYTHON 3.7)
 环境说明
主要安装以tensorflow和pytorch这两个可以通过GPU进行计算的深度学习框架，并且在这两个计算框架的基础上安装kera"><meta name="keywords" content="大数据,机器学习,深度学习,人工智能"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">人肉智能的全干开发工程师</a></h3><div class="description"><p>大数据，机器学习，AI，数据挖掘的从业者，机器算命爱好者。</p></div></div></div><ul class="social-links"><li><a href="http://github.com/zergtant"><i class="fa fa-github"></i></a></li></ul><div class="footer"><span>Theme by </span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li><li><a href="/website">有用的网站</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>win10下通过Anaconda搭建深度学习环境GPU篇</a></h3></div><div class="post-content"><h1 id="win10下通过anaconda搭建深度学习环境gpu篇"><a class="markdownIt-Anchor" href="#win10下通过anaconda搭建深度学习环境gpu篇"></a> win10下通过Anaconda搭建深度学习环境GPU篇</h1>
<h2 id="环境准备"><a class="markdownIt-Anchor" href="#环境准备"></a> 环境准备</h2>
<p>Anaconda3-5.3.0-Windows-x86_64 (PYTHON 3.7)</p>
<h2 id="环境说明"><a class="markdownIt-Anchor" href="#环境说明"></a> 环境说明</h2>
<p>主要安装以tensorflow和pytorch这两个可以通过GPU进行计算的深度学习框架，并且在这两个计算框架的基础上安装keras,fastai和autokeras，最后再安装xgboost，因为xgboost也有可以通过GPU计算的版本，所以就一起安装了,版本如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">tensorflow 1.19.0</div><div class="line">pytorch 0.4.1</div><div class="line">keras 2.2.4</div><div class="line">autokeras</div><div class="line">fastai  1.0.5</div><div class="line">xgboost</div></pre></td></tr></table></figure>
<h2 id="安装步骤"><a class="markdownIt-Anchor" href="#安装步骤"></a> 安装步骤</h2>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 因为autokeras只支持3.6所以使用python3.6</span></div><div class="line">conda create -n dl python=3.6</div><div class="line">activate dl</div><div class="line"><span class="comment"># 安装tensorflow</span></div><div class="line"><span class="comment"># tensorflow 默认版本是使用的cuda8，我这台电脑是安装的cuda92所以需要找到别人编译好的安装包</span></div><div class="line"><span class="comment"># 安装包在这个地址，https://github.com/fo40225/tensorflow-windows-wheel 需要寻找跟自己的cuda版本对应的安装包进行下载后安装</span></div><div class="line">pip install --ignore-installed tensorflow_gpu-1.9.0-cp36-cp36m-win_amd64.whl</div><div class="line">pip install keras</div><div class="line"><span class="comment"># 安装pytorch，这是官方给的安装地址，就是下载速度有点慢</span></div><div class="line">conda install pytorch cuda92 -c pytorch</div><div class="line">pip install torchvision</div><div class="line"><span class="comment"># 安装fastai,fastai 已经包含了matplot等常用的包</span></div><div class="line">pip install fastai</div><div class="line"><span class="comment"># Cython加快sklearn 的计算速度，也一起装上</span></div><div class="line">pip install Cython --install-option=<span class="string">"--no-cython-compile"</span></div><div class="line">pip install sklearn</div><div class="line"><span class="comment"># 安装autokeras</span></div><div class="line">pip install autokeras</div><div class="line"><span class="comment"># autokeras 会自动使用最新的tensorflow 覆盖掉以前版本，所以安装完后需要从新再装一遍tensorflow</span></div></pre></td></tr></table></figure>
<h2 id="安装xgboost"><a class="markdownIt-Anchor" href="#安装xgboost"></a> 安装xgboost</h2>
<p>xgboost的GPU版本需要下载源代码并且自己安装所以单独出来写<br>
国外大神已经把编译好的放到网上了，所以就不用自己编译了，地址这里：<a href="http://ssl.picnet.com.au/xgboost/" target="_blank" rel="external">http://ssl.picnet.com.au/xgboost/</a> 。左边是cpu版，右边是支持gpu加速版。点击需要的版本下载xgboost.dll就可以了</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># clone 源代码</span></div><div class="line">git <span class="built_in">clone</span> --recursive https://github.com/dmlc/xgboost</div><div class="line"><span class="comment"># 下载好的xgboost.dll 复制到python-package\xgboost目录，并进入python-package目录，执行以下命令行</span></div><div class="line">python setup.py install</div><div class="line"><span class="comment"># 在安装过程中的进度中会出现复制xgboost.dll的命令，查看下进度记录即可确认安装的是GPU版本</span></div></pre></td></tr></table></figure>
<h2 id="验证"><a class="markdownIt-Anchor" href="#验证"></a> 验证</h2>
<h3 id="验证-tensorflow"><a class="markdownIt-Anchor" href="#验证-tensorflow"></a> 验证 tensorflow</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">a = tf.constant([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], shape=[<span class="number">2</span>, <span class="number">3</span>], name=<span class="string">'a'</span>)</div><div class="line">b = tf.constant([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], shape=[<span class="number">3</span>, <span class="number">2</span>], name=<span class="string">'b'</span>)</div><div class="line">c = tf.matmul(a, b)</div><div class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=<span class="keyword">True</span>))</div><div class="line">print(sess.run(c))</div></pre></td></tr></table></figure>
<p>如果最后返回中信息包含了GPU的信息，说明tensorflow使用的是GPU进行计算</p>
<h3 id="验证-pytorch"><a class="markdownIt-Anchor" href="#验证-pytorch"></a> 验证 pytorch</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> torch</div><div class="line">torch.cuda.is_available()</div><div class="line">torch.cuda.device_count()</div><div class="line">torch.cuda.get_device_name(<span class="number">0</span>)</div></pre></td></tr></table></figure>
<p>torch会打印GPU的信息，如果出现就说明没有问题</p>
<h3 id="验证xgboost"><a class="markdownIt-Anchor" href="#验证xgboost"></a> 验证xgboost</h3>
<p>找到xgboost\demo\gpu_acceleration目录<br>
执行 <code>python cover_type.py</code> 即可</p>
<h2 id="问题解决"><a class="markdownIt-Anchor" href="#问题解决"></a> 问题解决</h2>
<p>如果你在import fast的时候出现以下错误</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">lib\importlib\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject</div><div class="line">  <span class="built_in">return</span> f(*args, **kwds)</div><div class="line">\lib\importlib\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject</div><div class="line">  <span class="built_in">return</span> f(*args, **kwds)</div></pre></td></tr></table></figure>
<p>说明是在导入spacy时出现了问题<br>
我这边安装的是cymem 2.0.2 可能是不兼容，切换到cymem 1.31.2后可以顺利导入<br>
或者使用更简单的方法</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">python uninstall Spacy</div><div class="line">conda install Spacy</div></pre></td></tr></table></figure>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2018-10-18</span><i class="fa fa-tag"></i></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://www.tantai.org/posts/install-keras-pytorch-jupyter-notebook-Anaconda-window-10-gpu/,人肉智能的全干开发工程师,win10下通过Anaconda搭建深度学习环境GPU篇,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a role="navigation" href="/posts/aws-gpu/" title="aws 深度学习环境常用命令" class="btn">上一篇</a></li><li class="next pagbuttons"><a role="navigation" href="/posts/hexo-error-fatal-httprequest-exception-encountered/" title="Hexo部署出现错误 fatal HttpRequestException encountered." class="btn">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script>var _hmt = _hmt || [];
(function() {
 var hm = document.createElement("script");
 hm.src = "https://hm.baidu.com/hm.js?215ef6fdd9b4757230418bbdaf4b74dc";
 var s = document.getElementsByTagName("script")[0]; 
 s.parentNode.insertBefore(hm, s);
})();</script></body></html>